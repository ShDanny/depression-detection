{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21fd18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lenovo\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.402 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 存储模型\n",
    "import pickle\n",
    "\n",
    "# data clean\n",
    "import re # punctuation,data clean\n",
    "\n",
    "# tokenization and feature extraction\n",
    "# install expacted word bag for jieba\n",
    "import jieba \n",
    "jieba.load_userdict('jieba_expanded_dict.txt')\n",
    "import jieba.analyse # TF-IDF \n",
    "import numpy as np # TF-IDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
    "\n",
    "# models\n",
    "from sklearn.ensemble import RandomForestClassifier # RF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# analyse\n",
    "import seaborn as sns # density curve \n",
    "import matplotlib.pyplot as plt # pie chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6671c069",
   "metadata": {},
   "source": [
    "# data preprocess, run this part every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95f7c364",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned_tokenization = pd.read_csv('balanced_df_all_cleaned_tokenization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b69334",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df_all_cleaned_tokenization2 = balanced_df_all_cleaned_tokenization.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a576fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID  label                                      tweet_content\n",
      "4358   11433      0  命 林俊杰 墙头 邓伦 墙头 越越 喜欢 点 失眠 南 印象 里 老林 厨房 白 变化 太 ...\n",
      "5213   11314      0  活 牢笼 里 包括 周遭 环境 机 跳出 找点 空间 里 找然 找 东莞 空调 风扇 齐开 ...\n",
      "6390   16325      0  欧美 机车 女郎 美胸 诱惑 消费 钱容力 分享 豆包 爱 表现 实挺错 感觉 养生 真 重...\n",
      "9226   27982      0  发快 手 作品 華少 快手 视频 妹妹 帮 哥哥 搞定 新 嫂子 涛涛 快手 视频 朋友 生...\n",
      "7988   22881      0  太累 想 做事 拒绝 事 勉强 喜欢 假装 没 听见 生讨善 山越 高路 越 陡见 风暴 中...\n",
      "...      ...    ...                                                ...\n",
      "12919   2595      1  段 痛苦 沉重 压抑 法 摆脱 感觉 沉重 实知 困境 夸 长久 思考 痛苦 削弱 绝 反击...\n",
      "20007   9683      1  明天 医院 复查 妈妈 商量 明天 出发 事聊 两 医院 两 医生 开药 副作 妈妈 说 接...\n",
      "15695   5371      1  说 清 孤独 原唯 表达 期 世界 摄影师 果吃家 饭 太 放心 苏芩 摄影师 想 温暖 利...\n",
      "10397     73      1  活 越久越 发觉 性 恐怖 越越 想 活活 煎熬 新增 度 恐慌 机场 接隔点 期间 确诊 ...\n",
      "15057   4733      1  生日 仪式 感然 命运 公 残酷 爱 鸭 买药 便 买 蛋糕 吃火锅 意外 收获 生日礼物 ...\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# 取500行label为0，500行label为1\n",
    "df_label_0 = balanced_df_all_cleaned_tokenization2[balanced_df_all_cleaned_tokenization2['label'] == 0].sample(n=500, random_state=41)\n",
    "df_label_1 = balanced_df_all_cleaned_tokenization2[balanced_df_all_cleaned_tokenization2['label'] == 1].sample(n=500, random_state=41)\n",
    "\n",
    "# 合并两个dataframe\n",
    "balanced_df_all_cleaned_tokenization2 = pd.concat([df_label_0, df_label_1])\n",
    "\n",
    "print(balanced_df_all_cleaned_tokenization2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c500554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN values with an empty string\n",
    "balanced_df_all_cleaned_tokenization2['tweet_content'] = balanced_df_all_cleaned_tokenization2['tweet_content'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da42ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TfidfVectorizer object 将tweet_content列作为特征向量化\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa28249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and transform the data\n",
    "X = vectorizer.fit_transform(balanced_df_all_cleaned_tokenization2['tweet_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "728d0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将label列作为目标变量\n",
    "y = balanced_df_all_cleaned_tokenization2['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9ee5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25603e00",
   "metadata": {},
   "source": [
    "## train SVM, only run this part first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fb24c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16ca43f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练SVM模型\n",
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e265a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试集的label\n",
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8aa38d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine:\n",
      "Accuracy: 0.9166666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.8251748251748252\n",
      "F1 Score: 0.9042145593869731\n"
     ]
    }
   ],
   "source": [
    "# 计算SVM模型评估指标\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc)\n",
    "recall_svc = recall_score(y_test, y_pred_svc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "print('\\nSupport Vector Machine:')\n",
    "print('Accuracy:', accuracy_svc)\n",
    "print('Precision:', precision_svc)\n",
    "print('Recall:', recall_svc)\n",
    "print('F1 Score:', f1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a45850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_tweet_content label:\n",
      "SVM: [1]\n"
     ]
    }
   ],
   "source": [
    "# normal content\n",
    "# new_tweet_content = ['这是 一条 新的 正常 推文']\n",
    "\n",
    "# depressed content\n",
    "new_tweet_content = ['思诺思 舒乐安定 代开 抑郁 抑郁 疫情 期间 开药 困难 开药 断药 关注 南京 兼职 超话志道 合盆友 解释 快 超话 传送门 南京 兼职']\n",
    "\n",
    "# feature extraction\n",
    "new_X = vectorizer.transform(new_tweet_content)\n",
    "\n",
    "# SVM\n",
    "new_y_pred_svc = svc.predict(new_X)\n",
    "\n",
    "print('\\nnew_tweet_content label:')\n",
    "print('SVM:', new_y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0b628",
   "metadata": {},
   "source": [
    "# 存储模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e53a78e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # %whos # 查看变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f149b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open('svm_test.pkl', 'wb') as file:\n",
    "    pickle.dump(svc, file)\n",
    "# dump(): 将数据序列化到文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e87db",
   "metadata": {},
   "source": [
    "# after spliting the dataset, load model, start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5aacb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loade model\n",
    "with open('svm_test.pkl', 'rb') as file:\n",
    "    svc = pickle.load(file)\n",
    "# load(): 将序列化后的数据读出（反序列化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b7a4461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型\n",
    "# 预测测试集的label\n",
    "# y_pred_svc = loaded_model.predict(X_test)\n",
    "y_pred_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bada3f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6470e539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_tweet_content label:\n",
      "SVM: [1]\n"
     ]
    }
   ],
   "source": [
    "# normal content\n",
    "# new_tweet_content = ['这是 一条 新的 正常 推文']\n",
    "\n",
    "# depressed content\n",
    "new_tweet_content = ['思诺思 舒乐安定 代开 抑郁 抑郁 疫情 期间 开药 困难 开药 断药 关注 南京 兼职 超话志道 合盆友 解释 快 超话 传送门 南京 兼职']\n",
    "\n",
    "# feature extraction\n",
    "new_X = vectorizer.transform(new_tweet_content)\n",
    "\n",
    "# SVM\n",
    "new_y_pred_svc = svc.predict(new_X)\n",
    "\n",
    "print('\\nnew_tweet_content label:')\n",
    "print('SVM:', new_y_pred_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50738c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Support Vector Machine:\n",
      "Accuracy: 0.97\n",
      "Precision: 1.0\n",
      "Recall: 0.9470588235294117\n",
      "F1 Score: 0.972809667673716\n"
     ]
    }
   ],
   "source": [
    "# 计算SVM模型评估指标\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc)\n",
    "recall_svc = recall_score(y_test, y_pred_svc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "print('\\nSupport Vector Machine:')\n",
    "print('Accuracy:', accuracy_svc)\n",
    "print('Precision:', precision_svc)\n",
    "print('Recall:', recall_svc)\n",
    "print('F1 Score:', f1_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f6f273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed0d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679977b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78205a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8504020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37057084",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.dumps(svc)\n",
    "with open('svm_test2.model','wb+') as f:#注意此处mode是'wb+'，表示二进制写入\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "828f95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pickle.dumps(svc)\n",
    "with open('svm_test2.model','wb+') as f:#注意此处mode是'wb+'，表示二进制写入\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d965524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de0cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model method3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8a2a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "327b6035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_test.joblib']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存模型\n",
    "joblib.dump(svc, 'svm_test.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ae5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型读取\n",
    "loaded_model = joblib.load('svm_test.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
